from fastapi import APIRouter, Response, Depends, status, Query, File, UploadFile, HTTPException

from varavu_selavu_service.models.api_models import (
    ExpenseRequest,
    ReceiptParseResponse,
    ExpenseWithItemsRequest,
    ExpenseWithItemsResponse,
    ChatRequest,
    HealthResponse,
    DashboardResponse,
    ExpenseCreatedResponse,
    AnalysisResponse,
    ChatResponse,
    ModelListResponse,
)
from varavu_selavu_service.services.expense_service import ExpenseService
from varavu_selavu_service.services.receipt_service import ReceiptService
from varavu_selavu_service.repo.sheets_repo import SheetsRepo
from varavu_selavu_service.services.chat_service import (
    call_chat_model,
    list_openai_models,
    list_ollama_models,
)
from varavu_selavu_service.services.analysis_service import AnalysisService
from varavu_selavu_service.core.config import Settings
from threading import RLock
from varavu_selavu_service.auth.routers import router as auth_router
from varavu_selavu_service.auth.security import auth_required

settings = Settings()

router = APIRouter(prefix="/api/v1")
router.include_router(auth_router)

# Dependency providers
def get_expense_service() -> ExpenseService:
    return ExpenseService()
# Simple in-memory cache for analysis results
_ANALYSIS_CACHE: dict[
    tuple[str, int | None, int | None, str | None, str | None],
    tuple[float, dict],
] = {}
_ANALYSIS_CACHE_TTL_SEC = 60  # adjust as needed
_CACHE_LOCK = RLock()

def get_analysis_service() -> AnalysisService:
    # Reuse a singleton instance to preserve in-memory cache across requests
    return _analysis_service_singleton

# Create the singleton instance
_analysis_service_singleton = AnalysisService(ttl_sec=settings.ANALYSIS_CACHE_TTL_SEC)


def get_receipt_service() -> ReceiptService:
    return ReceiptService(engine=settings.OCR_ENGINE)


def get_sheets_repo() -> SheetsRepo:
    return SheetsRepo()

@router.get("/healthz", response_model=HealthResponse, tags=["Health"], summary="Liveness probe")
def health_check():
    return {"status": "healthy"}

@router.get("/readyz", response_model=HealthResponse, tags=["Health"], summary="Readiness probe")
def readiness_check():
    # Extend with checks to downstream services (e.g., Google Sheets) if needed
    return {"status": "healthy"}


@router.post(
    "/expenses",
    status_code=status.HTTP_201_CREATED,
    response_model=ExpenseCreatedResponse,
    tags=["Expenses"],
    summary="Create a new expense",
)
def create_expense(
    data: ExpenseRequest,
    expense_service: ExpenseService = Depends(get_expense_service),
    analysis_service: AnalysisService = Depends(get_analysis_service),
    _: str = Depends(auth_required),
):
    saved = expense_service.add_expense(
        user_id=data.user_id,
        date=data.date,
        description=data.description,
        category=data.category,
        cost=data.cost,
    )
    # Invalidate analysis cache on writes
    analysis_service.invalidate_cache()
    # Normalize to response model shape
    expense_payload = {
        "user_id": saved.get("User ID", data.user_id),
        "date": data.date,
        "description": saved.get("description", data.description),
        "category": saved.get("category", data.category),
        "cost": float(saved.get("cost", data.cost)),
    }
    return {"success": True, "expense": expense_payload}


@router.get("/dashboard", response_model=DashboardResponse, tags=["Dashboard"], summary="Basic dashboard metrics")
def dashboard():
    # Dummy dashboard data
    return {
        "total_expenses": 1234.56,
        "total_categories": 12,
        "months_tracked": 5
    }

@router.get(
    "/analysis",
    response_model=AnalysisResponse,
    tags=["Analysis"],
    summary="Get expense analysis",
)
def analysis(
    user_id: str,
    year: int | None = Query(default=None, ge=1970, le=2100),
    month: int | None = Query(default=None, ge=1, le=12),
    start_date: str | None = None,
    end_date: str | None = None,
    response: Response = None,
    analysis_service: AnalysisService = Depends(get_analysis_service),
    _: str = Depends(auth_required),
):
    """Return analysis for a given user via the AnalysisService."""
    result = analysis_service.analyze(user_id=user_id, year=year, month=month, start_date=start_date, end_date=end_date, use_cache=True)
    if response is not None:
        # Align Cache-Control header with service TTL
        response.headers["Cache-Control"] = f"public, max-age={analysis_service.ttl_sec}"
    return result


@router.post(
    "/analysis/chat",
    response_model=ChatResponse,
    tags=["Analysis"],
    summary="Ask a question about your expenses",
)
def analysis_chat(
    request: ChatRequest,
    response: Response = None,
    analysis_service: AnalysisService = Depends(get_analysis_service),
    _: str = Depends(auth_required),
):
    """
    Accepts a chat query and returns a response generated by the chat model.
    In production the OpenAI API is used, while locally a running Ollama instance
    provides the responses. The query is sent together with the analysis data
    for the requested month (if any).

    The request body is validated by the `ChatRequest` Pydantic model.
    """
    # Reâ€‘use the AnalysisService to get the data for the requested month (fresh read for chat)
    analysis_result = analysis_service.analyze(
        user_id=request.user_id,
        year=request.year,
        month=request.month,
        start_date=request.start_date,
        end_date=request.end_date,
        use_cache=False,
    )

    # Pass the query + analysis to the appropriate chat model
    chat_response = call_chat_model(query=request.query, analysis=analysis_result, model=request.model)

    return {"response": chat_response}


@router.post(
    "/ingest/receipt/parse",
    response_model=ReceiptParseResponse,
    tags=["Expenses"],
    summary="OCR and parse a receipt without persisting",
)
def parse_receipt(
    file: UploadFile = File(...),
    save_ocr_text: bool = False,
    receipt_service: ReceiptService = Depends(get_receipt_service),
    _: str = Depends(auth_required),
):
    data = file.file.read()
    return receipt_service.parse(
        data,
        content_type=file.content_type or "image/png",
        save_ocr_text=save_ocr_text,
    )


@router.post(
    "/expenses/with_items",
    response_model=ExpenseWithItemsResponse,
    status_code=status.HTTP_201_CREATED,
    tags=["Expenses"],
    summary="Create an expense with itemized lines",
)
def create_expense_with_items(
    payload: ExpenseWithItemsRequest,
    sheets_repo: SheetsRepo = Depends(get_sheets_repo),
    _: str = Depends(auth_required),
    force: bool = Query(False),
):
    header = payload.header
    items = [i.dict(exclude_unset=True) for i in payload.items]
    required_header = ["purchased_at", "amount_cents"]
    for field in required_header:
        if field not in header:
            raise HTTPException(status_code=400, detail=f"Missing header field {field}")
    for item in items:
        if "item_name" not in item or "line_total_cents" not in item:
            raise HTTPException(status_code=400, detail="Invalid item")
    subtotal = sum(i.get("line_total_cents", 0) for i in items)
    tax = header.get("tax_cents", 0)
    tip = header.get("tip_cents", 0)
    discount = header.get("discount_cents", 0)
    if abs(subtotal + tax + tip - discount - header["amount_cents"]) > 2:
        raise HTTPException(status_code=400, detail="Totals do not reconcile")
    existing = sheets_repo.find_expense_by_fingerprint(payload.user_email, header.get("fingerprint", ""))
    if existing and not force:
        raise HTTPException(status_code=409, detail={"expense_id": existing.get("id")})
    expense_id = sheets_repo.append_expense({**header, "user_email": payload.user_email})
    try:
        item_ids = sheets_repo.append_items(payload.user_email, expense_id, items)
    except Exception:
        sheets_repo.delete_expense(expense_id)
        raise
    return {"expense_id": expense_id, "item_ids": item_ids}


@router.get(
    "/models",
    response_model=ModelListResponse,
    tags=["Models"],
    summary="List available LLM models (OpenAI in prod, Ollama locally)",
)
def list_models():
    """Return provider and available model ids based on environment."""
    env = settings.ENVIRONMENT or "local"
    if env.lower() in {"prod", "production"}:
        models = list_openai_models()
        return {"provider": "openai", "models": models}
    models = list_ollama_models()
    return {"provider": "ollama", "models": models}

